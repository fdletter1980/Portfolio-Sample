{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bea02e5",
   "metadata": {},
   "source": [
    "# Provision and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc282cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all relevant libraries\n",
    "#pip install langchain\n",
    "#pip install unstructured\n",
    "#pip install \"unstructured[pdf]\"\n",
    "#pip install pypdf\n",
    "#pip install tiktoken\n",
    "#pip install chromadb\n",
    "#pip install openai\n",
    "#pip install sentence_transformers\n",
    "#pip install langkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76a4ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.22.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ae10b26",
   "metadata": {},
   "source": [
    "We need to rightsize some library versions to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3eff963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d8d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --user chromadb==0.3.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a49e24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "openai_key=os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb7e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant Libraries\n",
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.document_loaders import OnlinePDFLoader, UnstructuredPDFLoader, PyPDFLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9abc8ac",
   "metadata": {},
   "source": [
    "# Load your Knowledge Base Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056ec953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = ''\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = DirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5908184",
   "metadata": {},
   "source": [
    "# Chunk and Embed into a Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1867f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "docs = split_docs(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40435693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62747193",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"chroma_db\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs, embedding=embeddings, persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b240f81",
   "metadata": {},
   "source": [
    "# Create Conversational Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "752ec586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:173: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", output_key='answer',return_messages=True)\n",
    "chatQA = ConversationalRetrievalChain.from_llm(\n",
    "            OpenAI(openai_api_key=openai_key,\n",
    "               temperature=0, model_name=\"gpt-3.5-turbo\"), \n",
    "            vectordb.as_retriever(search_kwargs={\"additional\": [\"vector\", \"certainty\", \"id\"]}), \n",
    "            return_source_documents=True,\n",
    "            #verbose=True,\n",
    "            #callbacks=[whylabs],\n",
    "            memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39219799",
   "metadata": {},
   "source": [
    "# Install LLM Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e6c4771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\frede\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized anonymous session with id session-mZfqt6N2 in config C:\\Users\\frede\\AppData\\Local\\whylogs\\whylogs\\config.ini\n"
     ]
    }
   ],
   "source": [
    "#Install monitoring\n",
    "from langkit import llm_metrics\n",
    "import whylogs as why\n",
    "\n",
    "why.init(session_type='whylabs_anonymous')\n",
    "schema = llm_metrics.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "852c0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del prompt_and_response\n",
    "\n",
    "prompt_and_response = {\n",
    "      \"prompt\": [],\n",
    "      \"response\": []\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f3688",
   "metadata": {},
   "source": [
    "# Start Interrogating the Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffa506ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the dimensions and volume of the refrigerator??\n",
      "ANSWER: The dimensions and volume of the refrigerator are as follows:\n",
      "- Height With Hinge: 70\"\n",
      "- Height Without Hinge: 68 3/10\"\n",
      "- Width: 36\"\n",
      "- Width of Cabinet: 35 6/10\"\n",
      "- Depth of Cabinet: 28 1/2\"\n",
      "- Depth With Door: 33 3/10\"\n",
      "- Depth With Door 90¬∞ Open: 48 1/2\"\n",
      "- Depth With Door and Handle: 35 7/10\"\n",
      "- Freezer Capacity: 9 Cu. Ft.\n",
      "- Fresh Food Capacity: 18.8 Cu. Ft.\n",
      "- Total Capacity: 27.8 Cu. Ft., SOURCES: {'C:\\\\Machine Learning\\\\Knowledge Base\\\\FRFS2823A_EN.pdf'}, CHUNK: {None}\n",
      "Question: How do you remove the refrigerator doors?\n",
      "ANSWER: To remove the refrigerator doors, you need to follow these steps:\n",
      "1. Remove the three screws from both hinge covers on the left and right top of the cabinet.\n",
      "2. After removing the hinge covers, disconnect any harnesses between the cabinet and doors by grasping both sides of the connector firmly, depress the latch, and pull apart.\n",
      "3. Remove the bulkhead cover at the rear of the unit to access the water tubing.\n",
      "4. Disconnect the water tube at the push-lock connection on the rear of the unit below the bulkhead.\n",
      "5. Pull the water tube out of the conduit from the top of the cabinet., SOURCES: {'C:\\\\Machine Learning\\\\Knowledge Base\\\\Refridgerator Manuel.pdf'}, CHUNK: {None}\n",
      "Question: done\n",
      "ANSWER: To remove the refrigerator doors, follow these steps:\n",
      "\n",
      "1. Pull the water tube out of the conduit from the top of the cabinet.\n",
      "2. Open both doors to a 90 degree angle.\n",
      "3. Remove the hex screws from the top hinge plate, then remove the top hinge.\n",
      "4. Lift the doors off the bottom hinges and set them aside.\n",
      "5. Unscrew the three bottom hinge screws and remove the bottom hinges., SOURCES: {'C:\\\\Machine Learning\\\\Knowledge Base\\\\Refridgerator Manuel.pdf'}, CHUNK: {None}\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "qry = \"\"\n",
    "while qry != 'done':\n",
    "    qry = input('Question: ')\n",
    "    if qry != exit:\n",
    "        response = chatQA({\"question\": qry, \"chat_history\": chat_history})\n",
    "        #print(response[\"answer\"])\n",
    "        sources = [doc.metadata.get(\"source\") for doc in response[\"source_documents\"]]\n",
    "        chunk = [doc.metadata.get(\"chunk_id\") for doc in response[\"source_documents\"]]\n",
    "        content=f\"ANSWER: {response['answer']}, SOURCES: {set(sources)}, CHUNK: {set(chunk)}\"\n",
    "               \n",
    "        print(content)\n",
    "        \n",
    "        #Persist prompt and result in a dictionary\n",
    "        prompt_and_response[\"prompt\"].append(qry)\n",
    "        prompt_and_response[\"response\"].append(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788064b",
   "metadata": {},
   "source": [
    "# Review Monitoring Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9328d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Aggregated 3 rows into profile 'prompt_and_responses'\n",
      "\n",
      "Visualize and explore this profile with one-click\n",
      "üîç https://hub.whylabsapp.com/resources/model-1/profiles?profile=ref-uNpnrzzzgI9fu0pj&sessionToken=session-mZfqt6N2\n"
     ]
    }
   ],
   "source": [
    "results = why.log(pd.DataFrame(prompt_and_response),name=\"prompt_and_responses\", schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a80fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
